{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b9dfb631",
      "metadata": {
        "id": "b9dfb631"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# sys.path.append('algotrade/NN')\n",
        "# from algotrade.NN.x_transformers.x_transformers import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "\n",
        "# from algotrade.NN.run_experiment import *\n",
        "# from algotrade.NN.generate_data import *"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "746e6986",
      "metadata": {
        "id": "746e6986"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1de49706",
      "metadata": {
        "id": "1de49706"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "TAG = 'test'\n",
        "\n",
        "TASK_NAME = 'price'\n",
        "TRAIN_SIZE = 100_000\n",
        "VAL_SIZE = 2_000\n",
        "TEST_SIZE = 10_000\n",
        "NUM_INITS = 4\n",
        "\n",
        "\n",
        "NUM_BATCHES = int(4e5)\n",
        "BATCH_SIZE = 128\n",
        "GENERATE_EVERY  = 10000\n",
        "NUM_TOKENS = 10 + 2\n",
        "ENC_SEQ_LEN = 24\n",
        "DEC_SEQ_LEN = 48\n",
        "\n",
        "INPUT_LEN = 24"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a87cb25",
      "metadata": {
        "id": "7a87cb25"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ZefqWL3W7WkY",
      "metadata": {
        "id": "ZefqWL3W7WkY"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "WINDOW_SIZES = [7, 14, 28, 56, 224, 700, 1400]\n",
        "\n",
        "def get_increase_pct(prices, horizon=30):\n",
        "    res = np.vstack([prices.shift(-i).values for i in range(horizon)])\n",
        "    max_value_in_horizon = np.nanmax(res, axis=0)\n",
        "    return max_value_in_horizon / prices\n",
        "    \n",
        "\n",
        "def add_ewm(df, col_name='Close', window_sizes=WINDOW_SIZES):\n",
        "    columns = []\n",
        "    for ws in window_sizes:\n",
        "        ewm = df[col_name].ewm(span=ws).mean()\n",
        "        df.loc[:, f'ewm_{col_name}_{ws}'] = ewm\n",
        "        columns.append(f'ewm_{col_name}_{ws}')\n",
        "    return columns\n",
        "\n",
        "\n",
        "def add_delta_pct(df, columns, col_name='Close'):\n",
        "    names = []\n",
        "    for col in columns:\n",
        "        name = f'{col}_delta_pct'\n",
        "        df.loc[:, name] = -(df[col_name] - df[col]) / df[col_name]\n",
        "        df.loc[df[col_name] == 0, name] = 0\n",
        "        names.append(name)\n",
        "    return names\n",
        "\n",
        "\n",
        "def add_exp_trend(df, price_col='Close'):\n",
        "    xs = np.array(list(df.index))\n",
        "    ys = np.log(df[price_col].values)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(xs.reshape(-1, 1), ys.reshape(-1, 1))\n",
        "    preds = model.predict(xs.reshape(-1, 1))\n",
        "\n",
        "    a = model.coef_[0]\n",
        "    b = preds[0] - xs[0] * a\n",
        "    df.loc[:, 'trend'] = np.exp(preds)\n",
        "    return a, b\n",
        "\n",
        "\n",
        "def add_linear_trend(df, price_col='Close'):\n",
        "    xs = np.array(list(df.index))\n",
        "    ys = df[price_col].values\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(xs.reshape(-1, 1), ys.reshape(-1, 1))\n",
        "    preds = model.predict(xs.reshape(-1, 1))\n",
        "\n",
        "    a = model.coef_[0]\n",
        "    b = preds[0] - xs[0] * a\n",
        "    df.loc[:, 'trend'] = preds\n",
        "    return a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "Nu65RVAS9eVQ",
      "metadata": {
        "id": "Nu65RVAS9eVQ"
      },
      "outputs": [],
      "source": [
        "def preprocess(data_path = 'algotrade/data/gemini_BTCUSD_1hr.csv',\n",
        "            save_path = 'algotrade/data/BTCUSD/',\n",
        "            train_size = 0.7,\n",
        "            val_size = 0.1,\n",
        "            test_size = 0.2,\n",
        "            shuffle = False,\n",
        "            # name = 'BTCUSD',\n",
        "            trend = 'exp',\n",
        "            price_col = 'Close',\n",
        "            start_token=-10_000):\n",
        "    \n",
        "    df = pd.read_csv(data_path)\n",
        "    df = df.reset_index()\n",
        "    df.columns = df.iloc[0]\n",
        "    df = df.iloc[1:].sort_values('Date').reset_index(drop=True)\n",
        "    for col in df.columns[-5:]:\n",
        "        df.loc[:, col] = df[col].astype(float)\n",
        "\n",
        "    price_df = df\n",
        "    price_df['DT'] = pd.to_datetime(price_df.Date)\n",
        "    price_df['Date'] = price_df.DT.dt.date\n",
        "\n",
        "    if trend == 'exp':\n",
        "        a, b = add_exp_trend(price_df)\n",
        "    else:\n",
        "        a, b = add_linear_trend(price_df)\n",
        "\n",
        "    ewm_cols = add_ewm(price_df, price_col)\n",
        "    delta_cols = add_delta_pct(price_df, ewm_cols + ['trend'], price_col)\n",
        "\n",
        "    vol_ewm_cols = add_ewm(price_df, 'Volume')\n",
        "    vol_delta_cols = add_delta_pct(price_df, vol_ewm_cols, 'Volume')\n",
        "\n",
        "    price_df[f'next_{price_col}'] = price_df[price_col].shift(-1)\n",
        "    delta_pct_col = add_delta_pct(price_df, [f'next_{price_col}'], price_col)[0]\n",
        "    next_price_col = f'next_{price_col}'\n",
        "\n",
        "    feature_columns = [price_col] + delta_cols + vol_delta_cols\n",
        "    target_columns = [delta_pct_col, next_price_col]\n",
        "\n",
        "    features = price_df[feature_columns].values[:-1]\n",
        "    target_ = price_df[target_columns].values[:-1]\n",
        "    target = np.ones((1 + target_.shape[1], target_.shape[0]))*start_token\n",
        "    target[1:, :] = target_.T\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target.T, train_size=train_size, shuffle=False)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=val_size/(1-train_size), shuffle=False)\n",
        "\n",
        "    # print('X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape')\n",
        "    # print(X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape)\n",
        "\n",
        "    names = ['X_train', 'X_test', 'X_val', 'y_train', 'y_test', 'y_val']\n",
        "    vars = [X_train, X_test, X_val, y_train, y_test, y_val]\n",
        "    os.system(f'mkdir {save_path}')\n",
        "    # os.system(f'mkdir {save_path+name}')\n",
        "    for name, var in zip(names, vars):\n",
        "        print(name, var.shape)\n",
        "        np.save(save_path+name+'.npy', var)\n",
        "    return price_df[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bSg4E2Xx90ji",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSg4E2Xx90ji",
        "outputId": "7bce0d79-40dd-4fbe-93d6-7e43068019ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train (36982, 16)\n",
            "X_test (10567, 16)\n",
            "X_val (5283, 16)\n",
            "y_train (36982, 3)\n",
            "y_test (10567, 3)\n",
            "y_val (5283, 3)\n"
          ]
        }
      ],
      "source": [
        "res = preprocess(data_path = '../data/gemini_BTCUSD_1hr.csv',\n",
        "            save_path = '../data/BTCUSD/',\n",
        "            train_size = 0.7,\n",
        "            val_size = 0.1,\n",
        "            test_size = 0.2,\n",
        "            shuffle = False,\n",
        "            # name = 'BTCUSD',\n",
        "            trend = 'exp',\n",
        "            price_col = 'Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3162aaa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# res[['Close', 'next_Close']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "046b0f4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.tensor(np.load('../data/BTCUSD/X_train.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "836a096f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([245.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,\n",
              "         -0.0000,   0.9505,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,\n",
              "         -0.0000,  -0.0000], dtype=torch.float64)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "84d9f8ce",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([36982, 16])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tgt_len = 24\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "3a9eed48",
      "metadata": {},
      "outputs": [],
      "source": [
        "slices = [X[i: tgt_len+i] for i in range(X.shape[0] - tgt_len)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "2827ef48",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([24, 36958, 16])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = torch.cat(slices).reshape(-1, tgt_len, X.shape[1])\n",
        "X_train = X_train.transpose(0,1)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "264625c7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2.4500e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  9.5053e-01, -0.0000e+00,\n",
              "         -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "         -0.0000e+00],\n",
              "        [ 2.4500e+02, -0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00,\n",
              "         -0.0000e+00, -0.0000e+00, -0.0000e+00,  9.5070e-01, -3.7019e-01,\n",
              "         -4.0104e-01, -4.1647e-01, -4.2418e-01, -4.2996e-01, -4.3128e-01,\n",
              "         -4.3158e-01],\n",
              "        [ 2.4492e+02,  1.8539e-04,  2.0186e-04,  2.0989e-04,  2.1385e-04,\n",
              "          2.1678e-04,  2.1745e-04,  2.1760e-04,  9.5151e-01, -3.9881e-02,\n",
              "         -7.1568e-02, -8.9048e-02, -9.8179e-02, -1.0520e-01, -1.0681e-01,\n",
              "         -1.0718e-01],\n",
              "        [ 2.4425e+02,  1.8578e-03,  2.0444e-03,  2.1342e-03,  2.1781e-03,\n",
              "          2.2104e-03,  2.2177e-03,  2.2194e-03,  9.5703e-01, -1.6261e-01,\n",
              "         -1.9498e-01, -2.1277e-01, -2.2206e-01, -2.2919e-01, -2.3083e-01,\n",
              "         -2.3121e-01],\n",
              "        [ 2.4499e+02, -7.8537e-04, -7.2603e-04, -6.8781e-04, -6.6689e-04,\n",
              "         -6.5051e-04, -6.4672e-04, -6.4582e-04,  9.5129e-01, -1.1296e-01,\n",
              "         -1.4796e-01, -1.6786e-01, -1.7838e-01, -1.8650e-01, -1.8837e-01,\n",
              "         -1.8882e-01],\n",
              "        [ 2.4400e+02,  2.2747e-03,  2.5583e-03,  2.7009e-03,  2.7716e-03,\n",
              "          2.8241e-03,  2.8360e-03,  2.8387e-03,  9.5938e-01, -4.0106e-02,\n",
              "         -7.2881e-02, -9.3024e-02, -1.0401e-01, -1.1263e-01, -1.1463e-01,\n",
              "         -1.1511e-01],\n",
              "        [ 2.4400e+02,  1.6184e-03,  2.0192e-03,  2.2276e-03,  2.3320e-03,\n",
              "          2.4098e-03,  2.4273e-03,  2.4315e-03,  9.5955e-01,  9.3428e-01,\n",
              "          9.7409e-01,  9.7787e-01,  9.7529e-01,  9.7135e-01,  9.7022e-01,\n",
              "          9.6994e-01],\n",
              "        [ 2.4400e+02,  1.1688e-03,  1.6243e-03,  1.8748e-03,  2.0028e-03,\n",
              "          2.0991e-03,  2.1209e-03,  2.1260e-03,  9.5972e-01,  1.1361e+01,\n",
              "          1.2932e+01,  1.3557e+01,  1.3815e+01,  1.3982e+01,  1.4017e+01,\n",
              "          1.4025e+01],\n",
              "        [ 2.4395e+02,  1.0026e-03,  1.4927e-03,  1.7777e-03,  1.9263e-03,\n",
              "          2.0392e-03,  2.0648e-03,  2.0709e-03,  9.6029e-01,  3.7917e+01,\n",
              "          4.7884e+01,  5.2448e+01,  5.4503e+01,  5.5918e+01,  5.6222e+01,\n",
              "          5.6293e+01],\n",
              "        [ 2.4395e+02,  7.3700e-04,  1.2311e-03,  1.5376e-03,  1.7013e-03,\n",
              "          1.8270e-03,  1.8557e-03,  1.8625e-03,  9.6046e-01, -4.8427e-01,\n",
              "         -4.7127e-01, -4.5961e-01, -4.5340e-01, -4.4883e-01, -4.4782e-01,\n",
              "         -4.4759e-01],\n",
              "        [ 2.4395e+02,  5.4463e-04,  1.0241e-03,  1.3428e-03,  1.5175e-03,\n",
              "          1.6534e-03,  1.6846e-03,  1.6919e-03,  9.6063e-01, -4.2431e-01,\n",
              "         -4.6870e-01, -4.8366e-01, -4.8944e-01, -4.9315e-01, -4.9392e-01,\n",
              "         -4.9410e-01],\n",
              "        [ 2.4360e+02,  1.4704e-03,  2.0622e-03,  2.4484e-03,  2.6589e-03,\n",
              "          2.8220e-03,  2.8593e-03,  2.8682e-03,  9.6362e-01,  7.0770e-02,\n",
              "          9.1624e-03, -1.5437e-02, -2.5660e-02, -3.2470e-02, -3.3920e-02,\n",
              "         -3.4257e-02],\n",
              "        [ 2.4360e+02,  1.0939e-03,  1.7365e-03,  2.1693e-03,  2.4077e-03,\n",
              "          2.5931e-03,  2.6356e-03,  2.6456e-03,  9.6379e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  8.1545e-04,  1.4689e-03,  1.9327e-03,  2.1930e-03,\n",
              "          2.3969e-03,  2.4438e-03,  2.4549e-03,  9.6396e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  6.0882e-04,  1.2471e-03,  1.7300e-03,  2.0075e-03,\n",
              "          2.2269e-03,  2.2776e-03,  2.2896e-03,  9.6413e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  4.5508e-04,  1.0621e-03,  1.5549e-03,  1.8457e-03,\n",
              "          2.0782e-03,  2.1322e-03,  2.1450e-03,  9.6431e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  3.4045e-04,  9.0685e-04,  1.4024e-03,  1.7034e-03,\n",
              "          1.9471e-03,  2.0039e-03,  2.0173e-03,  9.6448e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  2.5485e-04,  7.7598e-04,  1.2687e-03,  1.5774e-03,\n",
              "          1.8305e-03,  1.8898e-03,  1.9039e-03,  9.6465e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  1.9087e-04,  6.6521e-04,  1.1509e-03,  1.4651e-03,\n",
              "          1.7262e-03,  1.7878e-03,  1.8024e-03,  9.6482e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  1.4300e-04,  5.7114e-04,  1.0466e-03,  1.3644e-03,\n",
              "          1.6324e-03,  1.6960e-03,  1.7111e-03,  9.6499e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  1.0716e-04,  4.9102e-04,  9.5366e-04,  1.2736e-03,\n",
              "          1.5475e-03,  1.6129e-03,  1.6284e-03,  9.6516e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4360e+02,  8.0325e-05,  4.2261e-04,  8.7066e-04,  1.1915e-03,\n",
              "          1.4704e-03,  1.5373e-03,  1.5533e-03,  9.6533e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00],\n",
              "        [ 2.4363e+02, -3.2102e-05,  2.5796e-04,  6.8352e-04,  1.0013e-03,\n",
              "          1.2826e-03,  1.3506e-03,  1.3668e-03,  9.6526e-01, -6.1811e-01,\n",
              "         -3.2699e-01,  4.6061e-02,  2.9047e-01,  4.8786e-01,  5.3321e-01,\n",
              "          5.4388e-01],\n",
              "        [ 2.4363e+02, -2.4069e-05,  2.2242e-04,  6.2604e-04,  9.4031e-04,\n",
              "          1.2235e-03,  1.2924e-03,  1.3089e-03,  9.6543e-01,  0.0000e+00,\n",
              "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
              "          0.0000e+00]], dtype=torch.float64)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fc7dc21e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class data_loader:\n",
        "    def __init__(self, mode, path='data', tgt_len=24, batch_size=32, none_mask=True):\n",
        "        X, y = np.load(f'{path}/X_{mode}.npy'), np.load(f'{path}/y_{mode}.npy')\n",
        "        # self.X, self.y = torch.tensor(self.X).cuda(), \\\n",
        "        #                     torch.tensor(self.y).cuda()\n",
        "        X, y = torch.tensor(X), torch.tensor(y)\n",
        "        slices_x = [X[i: tgt_len+i] for i in range(X.shape[0] - tgt_len)]\n",
        "        slices_y = [y[i: tgt_len+i] for i in range(X.shape[0] - tgt_len)]\n",
        "\n",
        "        self.X, self.y = torch.cat(slices_x).reshape(-1, tgt_len, X.shape[1]),\\\n",
        "                         torch.cat(slices_y).reshape(-1, tgt_len, X.shape[1])\n",
        "        self.data_size = self.X.shape[0]\n",
        "        self.data_ptr = 0\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __next__(self):\n",
        "        X = self.X[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "        y = self.y[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "        \n",
        "        if not self.none_mask:\n",
        "            sm = self.src_masks[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "            sm = torch.tensor(sm).cuda()\n",
        "        else:\n",
        "            sm = None\n",
        "            \n",
        "        self.data_ptr = (self.data_ptr + self.batch_size) % self.data_size\n",
        "\n",
        "        return X, y, sm, self.tgt_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "_MSt7PKV-cds",
      "metadata": {
        "id": "_MSt7PKV-cds"
      },
      "outputs": [],
      "source": [
        "# class data_loader:\n",
        "#     def __init__(self, mode, path='data', batch_size=32, none_mask=True):\n",
        "#         X, y = np.load(f'{path}/X_{mode}.npy'), np.load(f'{path}/y_{mode}.npy')\n",
        "#         # self.X, self.y = torch.tensor(self.X).cuda(), \\\n",
        "#         #                     torch.tensor(self.y).cuda()\n",
        "#         X, y = torch.tensor(X), torch.tensor(y)\n",
        "#         slices_x = [X[i: tgt_len+i] for i in range(X.shape[0] - tgt_len)]\n",
        "#         slices_y = [y[i: tgt_len+i] for i in range(X.shape[0] - tgt_len)]\n",
        "\n",
        "#         self.X, self.y = torch.cat(slices_x).reshape(-1, tgt_len, X.shape[1]),\\\n",
        "#                          torch.cat(slices_y).reshape(-1, tgt_len, X.shape[1])\n",
        "#         self.data_size = self.X.shape[0]\n",
        "#         self.data_ptr = 0\n",
        "\n",
        "#         self.batch_size = batch_size\n",
        "\n",
        "#     def __next__(self):\n",
        "#         X = self.X[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "#         y = self.y[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "        \n",
        "#         if not self.none_mask:\n",
        "#             sm = self.src_masks[self.data_ptr: self.data_ptr+self.batch_size]\n",
        "#             sm = torch.tensor(sm).cuda()\n",
        "#         else:\n",
        "#             sm = None\n",
        "            \n",
        "#         self.data_ptr = (self.data_ptr + self.batch_size) % self.data_size\n",
        "\n",
        "#         return X, y, sm, self.tgt_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c118128",
      "metadata": {
        "id": "1c118128"
      },
      "source": [
        "### Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "ibxQ2_rDA6cZ",
      "metadata": {
        "id": "ibxQ2_rDA6cZ"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'algotrade/data/BTCUSD/X_train.npy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-c291940bd872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgen_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'algotrade/data/BTCUSD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgen_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'algotrade/data/BTCUSD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgen_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'algotrade/data/BTCUSD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-36deb563f143>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, path, batch_size, none_mask)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}/X_{mode}.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path}/y_{mode}.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# self.X, self.y = torch.tensor(self.X).cuda(), \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#                     torch.tensor(self.y).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/cudaenv/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'algotrade/data/BTCUSD/X_train.npy'"
          ]
        }
      ],
      "source": [
        "\n",
        "gen_train = data_loader(path=f'algotrade/data/BTCUSD', mode='train', batch_size=BATCH_SIZE)\n",
        "gen_val = data_loader(path=f'algotrade/data/BTCUSD', mode='val', batch_size=BATCH_SIZE)\n",
        "gen_test = data_loader(path=f'algotrade/data/BTCUSD', mode='test', batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eCeB4PeVTqyT",
      "metadata": {
        "id": "eCeB4PeVTqyT"
      },
      "outputs": [],
      "source": [
        "s, t, _, _ = next(gen_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1PJH19J1TtpR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PJH19J1TtpR",
        "outputId": "5413a745-4a3a-44ec-939c-a29fe7a895f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 15])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KIiuA3v357ou",
      "metadata": {
        "id": "KIiuA3v357ou"
      },
      "outputs": [],
      "source": [
        "class CXTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        dim,\n",
        "        tie_token_emb = False,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__()\n",
        "        enc_kwargs, kwargs = groupby_prefix_and_trim('enc_', kwargs)\n",
        "        dec_kwargs, kwargs = groupby_prefix_and_trim('dec_', kwargs)\n",
        "        \n",
        "        assert 'dim' not in enc_kwargs and 'dim' not in dec_kwargs, 'dimension of either encoder or decoder must be set with `dim` keyword'\n",
        "        enc_transformer_kwargs = pick_and_pop(['max_seq_len'], enc_kwargs)\n",
        "        # enc_transformer_kwargs['num_memory_tokens'] = enc_kwargs.pop('num_memory_tokens', None)\n",
        "\n",
        "        dec_transformer_kwargs = pick_and_pop(['max_seq_len'], dec_kwargs)\n",
        "\n",
        "        self.encoder = ContinuousTransformerWrapper(\n",
        "            **enc_transformer_kwargs,\n",
        "            attn_layers = Encoder(dim = dim, **enc_kwargs)\n",
        "        )\n",
        "\n",
        "        self.decoder = ContinuousTransformerWrapper(\n",
        "            **dec_transformer_kwargs,\n",
        "            attn_layers = Decoder(dim = dim, cross_attend = True, **dec_kwargs)\n",
        "        )\n",
        "\n",
        "        if tie_token_emb:\n",
        "            self.decoder.token_emb = self.encoder.token_emb\n",
        "\n",
        "        self.decoder = AutoregressiveWrapper(self.decoder)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, seq_in, seq_out_start, seq_len, src_mask = None, **kwargs):\n",
        "        encodings = self.encoder(seq_in, return_embeddings = True, mask = src_mask)\n",
        "        return self.decoder.generate(seq_out_start, seq_len, context = encodings, context_mask = src_mask, **kwargs)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask = None, tgt_mask = None):\n",
        "        enc = self.encoder(src, mask = src_mask, return_embeddings = True)\n",
        "\n",
        "        d = enc.shape[1] - src_mask.shape[1]\n",
        "        context_mask = src_mask[:, -d:]\n",
        "\n",
        "        out = self.decoder(tgt, context = enc, mask = tgt_mask, context_mask = context_mask)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jTkwLzz75eLp",
      "metadata": {
        "id": "jTkwLzz75eLp"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.0007\n",
        "\n",
        "model_parameters = ParameterGrid({'dim': [128],\n",
        "    'tie_token_embeds': [True],\n",
        "    'return_tgt_loss': [True],\n",
        "    'enc_depth': [2],\n",
        "    'enc_heads': [4],\n",
        "    'dec_depth': [2],\n",
        "    'dec_heads': [4],\n",
        "    'enc_max_seq_len': [15],\n",
        "    'dec_max_seq_len': [1],\n",
        "    # 'enc_num_memory_tokens': [2, 8, 0],\n",
        "    'dim_in': [None],\n",
        "    'dim_out': [1],\n",
        "    'emb_dim': [128],\n",
        "    'emb_dropout': [0.],\n",
        "    'use_pos_emb': [True]\n",
        "})\n",
        "\n",
        "param = list(model_parameters)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86Am7apyTY43",
      "metadata": {
        "id": "86Am7apyTY43"
      },
      "outputs": [],
      "source": [
        "model = CXTransformer(**param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CBA1JiQ0UsIk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "CBA1JiQ0UsIk",
        "outputId": "2f6c86f0-bf40-426c-a928-be8f5cfaf6ee"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-602a3ccc0412>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-dfeb3daa9087>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/algotrade/NN/x_transformers/x_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_embeddings, mask, return_attn, mems, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     ):\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
          ]
        }
      ],
      "source": [
        "model(s, t, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92978633",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "92978633",
        "outputId": "987a72c7-f896-4f19-86ce-11afe1ede53d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a9732fcda0c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mprint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTAG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         overfit_stop=False)\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTASK_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTAG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrive_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'test_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/algotrade/NN/run_experiment.py\u001b[0m in \u001b[0;36mtrain_validate_model\u001b[0;34m(model, train_generator, val_generator, optim, model_name, config, generate_every, num_batches, verbose, overfit_stop, print_file, tag, head_start)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/algotrade/NN/x_transformers/x_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msrc_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/algotrade/NN/x_transformers/x_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_embeddings, mask, return_mems, return_attn, mem, mems, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_mem\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.DoubleTensor instead (while checking arguments for embedding)"
          ]
        }
      ],
      "source": [
        "drive_path = 'drive/MyDrive/stocks_logs/'\n",
        "print_file = f'{drive_path}{TAG}_logs.txt'\n",
        "t = time.time()\n",
        "for init_num in range(NUM_INITS):\n",
        "    with open(print_file, 'a') as f:\n",
        "        f.write('\\n\\nInit number ' + str(init_num)+'\\n')\n",
        "    for i, param in enumerate(list(model_parameters)):\n",
        "        with open(print_file, 'a') as f:\n",
        "            f.write('\\n\\n' + str(param)+'\\n')\n",
        "        param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
        "        param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
        "        param.pop('depth,heads')\n",
        "\n",
        "        with open(print_file, 'a') as f:\n",
        "            f.write(f'{i / len(model_parameters) * 100}%')\n",
        "        model = XTransformer(**param).cuda()\n",
        "\n",
        "        model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_{TAG}_v{init_num}\"\n",
        "\n",
        "        optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "        train_validate_model(model, \n",
        "                        train_generator=gen_train, \n",
        "                        val_generator=gen_val, \n",
        "                        optim=optim, \n",
        "                        model_name=model_name, \n",
        "                        config=param,\n",
        "                        num_batches=NUM_BATCHES,\n",
        "                        generate_every=GENERATE_EVERY,\n",
        "                        print_file=print_file,\n",
        "                        tag=TAG,\n",
        "                        overfit_stop=False)\n",
        "        test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, log_path=drive_path+'test_results.csv')\n",
        "        with open(print_file, 'a') as f:\n",
        "            f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
        "        t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1xsvN-ny_a_X",
      "metadata": {
        "id": "1xsvN-ny_a_X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b0f5d48a",
      "metadata": {
        "id": "b0f5d48a"
      },
      "source": [
        "### Refit models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbfb752e",
      "metadata": {
        "id": "cbfb752e"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# def load_cpt(config, v, task_name, input_length):\n",
        "#     for fns in os.walk('checkpoints'):\n",
        "#         model_names = fns[2]\n",
        "        \n",
        "#     prefix = '{task_name}_dim{dim}d{d}h{h}M{M}l{l}'\n",
        "#     name = prefix.format(task_name=task_name,\n",
        "#                         dim=config['dim'],\n",
        "#                         d=config['enc_depth'], h=config['enc_heads'], \n",
        "#                         M=config['enc_num_memory_tokens'], \n",
        "#                         l=input_length)\n",
        "\n",
        "#     checkpoint_paths = ['checkpoints/' + n for n in model_names if name in n]\n",
        "#     cpt = torch.load(checkpoint_paths[v])\n",
        "#     bn, model_state, optim_state = cpt['batch_num'], cpt['state_dict'], cpt['optimizer']\n",
        "\n",
        "#     model = XTransformer(**config).cuda()\n",
        "#     model.load_state_dict(model_state)\n",
        "\n",
        "#     optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "#     optim.load_state_dict(optim_state)\n",
        "\n",
        "#     return bn, model, optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396ecf0a",
      "metadata": {
        "id": "396ecf0a"
      },
      "outputs": [],
      "source": [
        "# TAG = 'refit_to_max'\n",
        "# LEARNING_RATE = 0.001\n",
        "\n",
        "# path = f\"checkpoints/{TASK_NAME}{INPUT_LEN}/\"\n",
        "\n",
        "# for name in next(os.walk(path))[2]:\n",
        "#     print(name)\n",
        "#     if name == 'copy24_dim128d2h4M12l12_10tkn_len24_v2_10tkn_len24.pt':\n",
        "#         continue\n",
        "#     cpt = torch.load(path+name)\n",
        "#     print(cpt['batch_num'])\n",
        "#     delta_batches = NUM_BATCHES - cpt['batch_num'] - 1\n",
        "#     if delta_batches < 1:\n",
        "#         continue\n",
        "    \n",
        "#     split = name.split('_')\n",
        "#     config = {'dec_max_seq_len': DEC_SEQ_LEN,\n",
        "#          'dec_num_tokens': NUM_TOKENS,\n",
        "#          'dim': int(split[1].split('dim')[1].split('d')[0]),\n",
        "#          'enc_max_seq_len': int(split[1].split('M')[1].split('l')[1]),\n",
        "#          'enc_num_memory_tokens': int(split[1].split('M')[1].split('l')[0]),\n",
        "#          'enc_num_tokens': NUM_TOKENS,\n",
        "#          'return_tgt_loss': True,\n",
        "#          'tie_token_embeds': True,\n",
        "#          'enc_depth': int(split[1][3:].split('d')[1].split('h')[0]),\n",
        "#          'enc_heads': int(split[1][3:].split('d')[1].split('h')[1].split('M')[0]),\n",
        "#          'dec_depth': int(split[1][3:].split('d')[1].split('h')[0]),\n",
        "#          'dec_heads': int(split[1][3:].split('d')[1].split('h')[1].split('M')[0]),\n",
        "#          'tag': TAG,\n",
        "#          'task_name': TASK_NAME}\n",
        "    \n",
        "    \n",
        "#     gen_train = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE)\n",
        "#     gen_val = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE)\n",
        "#     gen_test = data_loader(path=f'data{INPUT_LEN}', task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE)\n",
        "\n",
        "\n",
        "#     print_file = f'logs/{TASK_NAME}_{TAG}_memory_logs.txt'\n",
        "#     t = time.time()\n",
        "#     with torch.cuda.device(0):\n",
        "#         with open(print_file, 'a') as f:\n",
        "#             f.write('\\n\\n' + str(config)+'\\n')\n",
        "#             f.write(str(delta_batches) + ' batches to go.\\n')\n",
        "\n",
        "#         print('\\n\\n' + str(config)+'\\n')\n",
        "#         print(str(delta_batches) + ' batches to go.\\n')\n",
        "#         model_name = name\n",
        "#         model = XTransformer(**config).cuda()\n",
        "#         optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "        \n",
        "#         model.load_state_dict(cpt['state_dict'])\n",
        "#         optim.load_state_dict(cpt['optimizer'])\n",
        "\n",
        "#         train_validate_model(model, \n",
        "#                             train_generator=gen_train, \n",
        "#                             val_generator=gen_val, \n",
        "#                             optim=optim, \n",
        "#                             model_name=model_name, \n",
        "#                             config=config,\n",
        "#                             num_batches=delta_batches,\n",
        "#                             generate_every=GENERATE_EVERY,\n",
        "#                             print_file=print_file,\n",
        "#                             tag=TAG,\n",
        "#                             overfit_stop=False)\n",
        "#         test_model(model, gen_test, model_name, config, TASK_NAME, tag=TAG)\n",
        "\n",
        "#         with open(print_file, 'a') as f:\n",
        "#             f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
        "#         t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a43009a",
      "metadata": {
        "id": "2a43009a"
      },
      "outputs": [],
      "source": [
        "test_model(model, gen_test, model_name, config, TASK_NAME, tag=TAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "981a173d",
      "metadata": {
        "id": "981a173d"
      },
      "outputs": [],
      "source": [
        "# gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "# gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "# gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=INPUT_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "\n",
        "\n",
        "# print_file = f'logs/{TASK_NAME}_{TAG}_memory_logs.txt'\n",
        "# t = time.time()\n",
        "# with torch.cuda.device(0):\n",
        "#     for init_num in range(NUM_INITS):\n",
        "#         with open(print_file, 'a') as f:\n",
        "#             f.write('\\n\\nInit number ' + str(init_num)+'\\n')\n",
        "#         for i, param in enumerate(list(model_parameters)):\n",
        "#             with open(print_file, 'a') as f:\n",
        "#                 f.write('\\n\\n' + str(param)+'\\n')\n",
        "#             param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
        "#             param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
        "#             param.pop('depth,heads')\n",
        "\n",
        "#             with open(print_file, 'a') as f:\n",
        "#                 f.write(f'{i / len(model_parameters) * 100}%')\n",
        "#             model = XTransformer(**param).cuda()\n",
        "\n",
        "#             model_name = f\"{TASK_NAME}{INPUT_LEN}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
        "\n",
        "#             optim = torch.optim.Adam(model.ффparameters(), lr=LEARNING_RATE)\n",
        "            \n",
        "#             bn, model, optim = load_cpt(param, v=init_num, task_name='copy55', input_length=param['enc_max_seq_len'])\n",
        "#             with open(print_file, 'a') as f:\n",
        "#                 f.write(f'BN: {bn}\\n')\n",
        "#             if bn < 130_000:\n",
        "#                 train_validate_model(model, \n",
        "#                                     train_generator=gen_train, \n",
        "#                                     val_generator=gen_val, \n",
        "#                                     optim=optim, \n",
        "#                                     model_name=model_name, \n",
        "#                                     dec_seq_len=DEC_SEQ_LEN,\n",
        "#                                     num_batches=NUM_BATCHES,\n",
        "#                                     generate_every=GENERATE_EVERY,\n",
        "#                                     print_file=print_file,\n",
        "#                                     tag=TAG,\n",
        "#                                     overfit_stop=False,\n",
        "#                                     head_start=(130_000 - bn)/GENERATE_EVERY)\n",
        "#                 test_model(model, gen_test, model_name, param, TASK_NAME, tag=TAG, dec_seq_len=param['dec_max_seq_len'])\n",
        "#             with open(print_file, 'a') as f:\n",
        "#                 f.write(f'\\nTotal time: {time.time() - t}\\n')\n",
        "#             t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c92dea",
      "metadata": {
        "id": "99c92dea"
      },
      "outputs": [],
      "source": [
        "from run_experiment import save_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e649122",
      "metadata": {
        "id": "4e649122"
      },
      "outputs": [],
      "source": [
        "# save_path = f'checkpoints/{model_name}_b{i}_{TAG}_maxval.pt'\n",
        "# save_cpt(save_path, model, optim)\n",
        "\n",
        "# if i // generate_every < head_start:\n",
        "#     continue\n",
        "\n",
        "# # early stopping\n",
        "# smoothed_val_scores = [np.mean(validation_scores[i-WINDOW_SIZE+1:i]) for i in range(WINDOW_SIZE-1, len(validation_scores))]\n",
        "\n",
        "# if overfit_stop and max(smoothed_val_scores) > max(smoothed_val_scores[-PATIENCE:]):\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "448fca13",
      "metadata": {
        "id": "448fca13"
      },
      "source": [
        "### Test!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b09847b7",
      "metadata": {
        "id": "b09847b7"
      },
      "outputs": [],
      "source": [
        "init_num = 0\n",
        "\n",
        "gen_train = data_loader(task_name=f'{TASK_NAME}_train', batch_size=BATCH_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "gen_val = data_loader(task_name=f'{TASK_NAME}_val', batch_size=VAL_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "gen_test = data_loader(task_name=f'{TASK_NAME}_test', batch_size=TEST_SIZE, enc_seq_len=ENC_SEQ_LEN, dec_seq_len=DEC_SEQ_LEN)\n",
        "\n",
        "\n",
        "param = list(model_parameters)[5]\n",
        "print(param)\n",
        "param['enc_depth'], param['enc_heads'] = param['depth,heads']\n",
        "param['dec_depth'], param['dec_heads'] = param['depth,heads']\n",
        "param.pop('depth,heads')\n",
        "\n",
        "model = XTransformer(**param).cuda()\n",
        "\n",
        "model_name = f\"{TASK_NAME}_dim{param['dim']}d{param['enc_depth']}h{param['enc_heads']}M{param['enc_num_memory_tokens']}l{param['enc_max_seq_len']}_v{init_num}\"\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "src, tgt, _, _ = next(gen_train)\n",
        "\n",
        "print(model.encoder.max_seq_len, model.encoder.num_memory_tokens)\n",
        "model.encoder(torch.cat((src, src)), return_embeddings=True).shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TF_emb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
